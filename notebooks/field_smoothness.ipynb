{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tinycudann as tcnn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sigma = 100\n",
    "device = torch.device('cuda')\n",
    "L = 16\n",
    "dim = 4\n",
    "encoding = tcnn.Encoding(3, dict(\n",
    "    otype=\"HashGrid\",\n",
    "    n_levels=L,\n",
    "    n_features_per_level=dim,\n",
    "    log2_hashmap_size=14,\n",
    "    base_resolution=16,\n",
    "    per_level_scale=2\n",
    ")).to(device)\n",
    "network = tcnn.Network(encoding.n_output_dims, 4, dict(\n",
    "    # otype=\"CutlassMLP\",\n",
    "    otype=\"FullyFusedMLP\",\n",
    "    activation=\"ReLU\",\n",
    "    output_activation=\"None\",\n",
    "    n_neurons=64,\n",
    "    n_hidden_layers=2,\n",
    "))\n",
    "# net = torch.nn.Sequential(\n",
    "#     encoding, network\n",
    "# ).to(device)\n",
    "\n",
    "d = 2*torch.rand(3, device=device)-1\n",
    "d = d / torch.linalg.norm(d)\n",
    "o = torch.zeros((3), device=device)\n",
    "\n",
    "t = torch.linspace(0, 0.1, 1000, device=device)\n",
    "inputs = o.reshape(1, 3) + t.reshape(-1, 1) * d.reshape(1, 3)\n",
    "output = encoding(inputs)\n",
    "# calculate normalization\n",
    "# output = output.reshape(-1, L, 4)\n",
    "output = output.reshape(-1, dim, L).permute(0, 2, 1)\n",
    "n = torch.arange(L, device=device)\n",
    "scaling = torch.erf(1 / (8*n*sigma).sqrt())\n",
    "output = output * scaling.reshape(1, -1, 1)\n",
    "# output = network(output.reshape(-1, L*dim))\n",
    "output = output.sum(dim=1)\n",
    "y = output[:, 1].detach().cpu()\n",
    "x = t.cpu()\n",
    "plt.plot(x, y)\n",
    "# plt.xlabel = \"t\"\n",
    "# plt.ylabel = \"network out\"\n",
    "plt.xlabel(\"t\")  # Use function call, not assignment\n",
    "plt.ylabel(\"network out\")  # Use function call, not assignment\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-9.0434e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(list(encoding.parameters())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Encoding in module tinycudann.modules object:\n",
      "\n",
      "class Encoding(Module)\n",
      " |  Encoding(n_input_dims, encoding_config, seed=1337, dtype=None)\n",
      " |  \n",
      " |  Input encoding to a neural network.\n",
      " |  \n",
      " |  Takes a `torch.float` input tensor of shape `[:, n_input_dims]` and maps\n",
      " |  it to a `dtype` tensor of shape `[:, self.n_output_dims]`, where\n",
      " |  `self.n_output_dims` depends on `n_input_dims` and the configuration\n",
      " |  `encoding_config`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_input_dims : `int`\n",
      " |          Determines the shape of input tensors as `[:, n_input_dims]`\n",
      " |  encoding_config: `dict`\n",
      " |          Configures the encoding. Possible configurations are documented at\n",
      " |          https://github.com/NVlabs/tiny-cuda-nn/blob/master/DOCUMENTATION.md\n",
      " |  seed: `int`\n",
      " |          Seed for pseudorandom parameter initialization\n",
      " |  dtype: `torch.dtype`\n",
      " |          Precision of the output tensor and internal parameters. A value\n",
      " |          of `None` corresponds to the optimally performing precision,\n",
      " |          which is `torch.half` on most systems. A value of `torch.float`\n",
      " |          may yield higher numerical accuracy, but is generally slower.\n",
      " |          A value of `torch.half` may not be supported on all systems.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Encoding\n",
      " |      Module\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_input_dims, encoding_config, seed=1337, dtype=None)\n",
      " |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Module:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Return state values to be pickled.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  extra_repr(self)\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should re-implement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  forward(self, x)\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__ = _wrapped_call_impl(self, *args, **kwargs)\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Default dir() implementation.\n",
      " |  \n",
      " |  __getattr__(self, name: str) -> Any\n",
      " |      # On the return type:\n",
      " |      # We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\n",
      " |      # This is done for better interop with various type checkers for the end users.\n",
      " |      # Having a stricter return type doesn't play nicely with `register_buffer()` and forces\n",
      " |      # people to excessively use type-ignores, asserts, casts, etc.\n",
      " |      # See full discussion on the problems with returning `Union` here\n",
      " |      # https://github.com/microsoft/pyright/issues/4213\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  add_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> @torch.no_grad()\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[1., 1.],\n",
      " |                  [1., 1.]], requires_grad=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[1., 1.],\n",
      " |                  [1., 1.]], requires_grad=True)\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  bfloat16(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf), buf.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  compile(self, *args, **kwargs)\n",
      " |      Compile this Module's forward using :func:`torch.compile`.\n",
      " |      \n",
      " |      This Module's `__call__` method is compiled and all arguments are passed as-is\n",
      " |      to :func:`torch.compile`.\n",
      " |      \n",
      " |      See :func:`torch.compile` for details on the arguments for this function.\n",
      " |  \n",
      " |  cpu(self: ~T) -> ~T\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self: ~T) -> ~T\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.eval()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  float(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``float`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  get_buffer(self, target: str) -> 'Tensor'\n",
      " |      Returns the buffer given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the buffer\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.Tensor: The buffer referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not a\n",
      " |              buffer\n",
      " |  \n",
      " |  get_extra_state(self) -> Any\n",
      " |      Returns any extra state to include in the module's state_dict.\n",
      " |      Implement this and a corresponding :func:`set_extra_state` for your module\n",
      " |      if you need to store extra state. This function is called when building the\n",
      " |      module's `state_dict()`.\n",
      " |      \n",
      " |      Note that extra state should be picklable to ensure working serialization\n",
      " |      of the state_dict. We only provide provide backwards compatibility guarantees\n",
      " |      for serializing Tensors; other objects may break backwards compatibility if\n",
      " |      their serialized pickled form changes.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: Any extra state to store in the module's state_dict\n",
      " |  \n",
      " |  get_parameter(self, target: str) -> 'Parameter'\n",
      " |      Returns the parameter given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the Parameter\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Parameter: The Parameter referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Parameter``\n",
      " |  \n",
      " |  get_submodule(self, target: str) -> 'Module'\n",
      " |      Returns the submodule given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      For example, let's say you have an ``nn.Module`` ``A`` that\n",
      " |      looks like this:\n",
      " |      \n",
      " |      .. code-block:: text\n",
      " |      \n",
      " |          A(\n",
      " |              (net_b): Module(\n",
      " |                  (net_c): Module(\n",
      " |                      (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n",
      " |                  )\n",
      " |                  (linear): Linear(in_features=100, out_features=200, bias=True)\n",
      " |              )\n",
      " |          )\n",
      " |      \n",
      " |      (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\n",
      " |      submodule ``net_b``, which itself has two submodules ``net_c``\n",
      " |      and ``linear``. ``net_c`` then has a submodule ``conv``.)\n",
      " |      \n",
      " |      To check whether or not we have the ``linear`` submodule, we\n",
      " |      would call ``get_submodule(\"net_b.linear\")``. To check whether\n",
      " |      we have the ``conv`` submodule, we would call\n",
      " |      ``get_submodule(\"net_b.net_c.conv\")``.\n",
      " |      \n",
      " |      The runtime of ``get_submodule`` is bounded by the degree\n",
      " |      of module nesting in ``target``. A query against\n",
      " |      ``named_modules`` achieves the same result, but it is O(N) in\n",
      " |      the number of transitive modules. So, for a simple check to see\n",
      " |      if some submodule exists, ``get_submodule`` should always be\n",
      " |      used.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the submodule\n",
      " |              to look for. (See above example for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Module: The submodule referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Module``\n",
      " |  \n",
      " |  half(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  ipu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the IPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on IPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict: Mapping[str, Any], strict: bool = True, assign: bool = False)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          If :attr:`assign` is ``True`` the optimizer must be created after\n",
      " |          the call to :attr:`load_state_dict`.\n",
      " |      \n",
      " |      Args:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |          assign (bool, optional): whether to assign items in the state\n",
      " |              dictionary to their corresponding keys in the module instead\n",
      " |              of copying them inplace into the module's current parameters and buffers.\n",
      " |              When ``False``, the properties of the tensors in the current\n",
      " |              module are preserved while when ``True``, the properties of the\n",
      " |              Tensors in the state dict are preserved.\n",
      " |              Default: ``False``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |      \n",
      " |      Note:\n",
      " |          If a parameter or buffer is registered as ``None`` and its corresponding key\n",
      " |          exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a\n",
      " |          ``RuntimeError``.\n",
      " |  \n",
      " |  modules(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |          ...     print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool, optional): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module. Defaults to True.\n",
      " |          remove_duplicate (bool, optional): whether to remove the duplicated buffers in the result. Defaults to True.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>     if name in ['running_var']:\n",
      " |          >>>         print(buf.size())\n",
      " |  \n",
      " |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo: Optional[Set[ForwardRef('Module')]] = None, prefix: str = '', remove_duplicate: bool = True)\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          memo: a memo to store the set of modules already added to the result\n",
      " |          prefix: a prefix that will be added to the name of the module\n",
      " |          remove_duplicate: whether to remove the duplicated module instances in the result\n",
      " |              or not\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |          ...     print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) -> Iterator[Tuple[str, torch.nn.parameter.Parameter]]\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |          remove_duplicate (bool, optional): whether to remove the duplicated\n",
      " |              parameters in the result. Defaults to True.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>     if name in ['bias']:\n",
      " |          >>>         print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param), param.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      This function is deprecated in favor of :meth:`~torch.nn.Module.register_full_backward_hook` and\n",
      " |      the behavior of this function will change in future versions.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name: str, tensor: Optional[torch.Tensor], persistent: bool = True) -> None\n",
      " |      Adds a buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the module's state. Buffers, by\n",
      " |      default, are persistent and will be saved alongside parameters. This\n",
      " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      " |      only difference between a persistent buffer and a non-persistent buffer\n",
      " |      is that the latter will not be a part of this module's\n",
      " |      :attr:`state_dict`.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor or None): buffer to be registered. If ``None``, then operations\n",
      " |              that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,\n",
      " |              the buffer is **not** included in the module's :attr:`state_dict`.\n",
      " |          persistent (bool): whether the buffer is part of this module's\n",
      " |              :attr:`state_dict`.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook: Union[Callable[[~T, Tuple[Any, ...], Any], Optional[Any]], Callable[[~T, Tuple[Any, ...], Dict[str, Any], Any], Optional[Any]]], *, prepend: bool = False, with_kwargs: bool = False, always_call: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      \n",
      " |      If ``with_kwargs`` is ``False`` or not specified, the input contains only\n",
      " |      the positional arguments given to the module. Keyword arguments won't be\n",
      " |      passed to the hooks and only to the ``forward``. The hook can modify the\n",
      " |      output. It can modify the input inplace but it will not have effect on\n",
      " |      forward since this is called after :func:`forward` is called. The hook\n",
      " |      should have the following signature::\n",
      " |      \n",
      " |          hook(module, args, output) -> None or modified output\n",
      " |      \n",
      " |      If ``with_kwargs`` is ``True``, the forward hook will be passed the\n",
      " |      ``kwargs`` given to the forward function and be expected to return the\n",
      " |      output possibly modified. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, args, kwargs, output) -> None or modified output\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user defined hook to be registered.\n",
      " |          prepend (bool): If ``True``, the provided ``hook`` will be fired\n",
      " |              before all existing ``forward`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``forward`` hooks on\n",
      " |              this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``forward`` hooks registered with\n",
      " |              :func:`register_module_forward_hook` will fire before all hooks\n",
      " |              registered by this method.\n",
      " |              Default: ``False``\n",
      " |          with_kwargs (bool): If ``True``, the ``hook`` will be passed the\n",
      " |              kwargs given to the forward function.\n",
      " |              Default: ``False``\n",
      " |          always_call (bool): If ``True`` the ``hook`` will be run regardless of\n",
      " |              whether an exception is raised while calling the Module.\n",
      " |              Default: ``False``\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook: Union[Callable[[~T, Tuple[Any, ...]], Optional[Any]], Callable[[~T, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Any, Dict[str, Any]]]]], *, prepend: bool = False, with_kwargs: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      \n",
      " |      \n",
      " |      If ``with_kwargs`` is false or not specified, the input contains only\n",
      " |      the positional arguments given to the module. Keyword arguments won't be\n",
      " |      passed to the hooks and only to the ``forward``. The hook can modify the\n",
      " |      input. User can either return a tuple or a single modified value in the\n",
      " |      hook. We will wrap the value into a tuple if a single value is returned\n",
      " |      (unless that value is already a tuple). The hook should have the\n",
      " |      following signature::\n",
      " |      \n",
      " |          hook(module, args) -> None or modified input\n",
      " |      \n",
      " |      If ``with_kwargs`` is true, the forward pre-hook will be passed the\n",
      " |      kwargs given to the forward function. And if the hook modifies the\n",
      " |      input, both the args and kwargs should be returned. The hook should have\n",
      " |      the following signature::\n",
      " |      \n",
      " |          hook(module, args, kwargs) -> None or a tuple of modified input and kwargs\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user defined hook to be registered.\n",
      " |          prepend (bool): If true, the provided ``hook`` will be fired before\n",
      " |              all existing ``forward_pre`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``forward_pre`` hooks\n",
      " |              on this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``forward_pre`` hooks registered with\n",
      " |              :func:`register_module_forward_pre_hook` will fire before all\n",
      " |              hooks registered by this method.\n",
      " |              Default: ``False``\n",
      " |          with_kwargs (bool): If true, the ``hook`` will be passed the kwargs\n",
      " |              given to the forward function.\n",
      " |              Default: ``False``\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_full_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to a module\n",
      " |      are computed, i.e. the hook will execute if and only if the gradients with\n",
      " |      respect to module outputs are computed. The hook should have the following\n",
      " |      signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> tuple(Tensor) or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\n",
      " |      with respect to the inputs and outputs respectively. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the input that will be used in place of :attr:`grad_input` in\n",
      " |      subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n",
      " |      as positional arguments and all kwarg arguments are ignored. Entries\n",
      " |      in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n",
      " |      arguments.\n",
      " |      \n",
      " |      For technical reasons, when this hook is applied to a Module, its forward function will\n",
      " |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      " |      of each Tensor returned by the Module's forward function.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |          Modifying inputs or outputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user-defined hook to be registered.\n",
      " |          prepend (bool): If true, the provided ``hook`` will be fired before\n",
      " |              all existing ``backward`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``backward`` hooks on\n",
      " |              this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``backward`` hooks registered with\n",
      " |              :func:`register_module_full_backward_hook` will fire before\n",
      " |              all hooks registered by this method.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_full_backward_pre_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients for the module are computed.\n",
      " |      The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_output) -> tuple[Tensor] or None\n",
      " |      \n",
      " |      The :attr:`grad_output` is a tuple. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the output that will be used in place of :attr:`grad_output` in\n",
      " |      subsequent computations. Entries in :attr:`grad_output` will be ``None`` for\n",
      " |      all non-Tensor arguments.\n",
      " |      \n",
      " |      For technical reasons, when this hook is applied to a Module, its forward function will\n",
      " |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      " |      of each Tensor returned by the Module's forward function.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |          Modifying inputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user-defined hook to be registered.\n",
      " |          prepend (bool): If true, the provided ``hook`` will be fired before\n",
      " |              all existing ``backward_pre`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``backward_pre`` hooks\n",
      " |              on this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``backward_pre`` hooks registered with\n",
      " |              :func:`register_module_full_backward_pre_hook` will fire before\n",
      " |              all hooks registered by this method.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_load_state_dict_post_hook(self, hook)\n",
      " |      Registers a post hook to be run after module's ``load_state_dict``\n",
      " |      is called.\n",
      " |      \n",
      " |      It should have the following signature::\n",
      " |          hook(module, incompatible_keys) -> None\n",
      " |      \n",
      " |      The ``module`` argument is the current module that this hook is registered\n",
      " |      on, and the ``incompatible_keys`` argument is a ``NamedTuple`` consisting\n",
      " |      of attributes ``missing_keys`` and ``unexpected_keys``. ``missing_keys``\n",
      " |      is a ``list`` of ``str`` containing the missing keys and\n",
      " |      ``unexpected_keys`` is a ``list`` of ``str`` containing the unexpected keys.\n",
      " |      \n",
      " |      The given incompatible_keys can be modified inplace if needed.\n",
      " |      \n",
      " |      Note that the checks performed when calling :func:`load_state_dict` with\n",
      " |      ``strict=True`` are affected by modifications the hook makes to\n",
      " |      ``missing_keys`` or ``unexpected_keys``, as expected. Additions to either\n",
      " |      set of keys will result in an error being thrown when ``strict=True``, and\n",
      " |      clearing out both missing and unexpected keys will avoid an error.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Alias for :func:`add_module`.\n",
      " |  \n",
      " |  register_parameter(self, name: str, param: Optional[torch.nn.parameter.Parameter]) -> None\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter or None): parameter to be added to the module. If\n",
      " |              ``None``, then operations that run on parameters, such as :attr:`cuda`,\n",
      " |              are ignored. If ``None``, the parameter is **not** included in the\n",
      " |              module's :attr:`state_dict`.\n",
      " |  \n",
      " |  register_state_dict_pre_hook(self, hook)\n",
      " |      These hooks will be called with arguments: ``self``, ``prefix``,\n",
      " |      and ``keep_vars`` before calling ``state_dict`` on ``self``. The registered\n",
      " |      hooks can be used to perform pre-processing before the ``state_dict``\n",
      " |      call is made.\n",
      " |  \n",
      " |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n",
      " |      Change if autograd should record operations on parameters in this\n",
      " |      module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.requires_grad_()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  set_extra_state(self, state: Any)\n",
      " |      This function is called from :func:`load_state_dict` to handle any extra state\n",
      " |      found within the `state_dict`. Implement this function and a corresponding\n",
      " |      :func:`get_extra_state` for your module if you need to store extra state within its\n",
      " |      `state_dict`.\n",
      " |      \n",
      " |      Args:\n",
      " |          state (dict): Extra state from the `state_dict`\n",
      " |  \n",
      " |  share_memory(self: ~T) -> ~T\n",
      " |      See :meth:`torch.Tensor.share_memory_`\n",
      " |  \n",
      " |  state_dict(self, *args, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing references to the whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      Parameters and buffers set to ``None`` are not included.\n",
      " |      \n",
      " |      .. note::\n",
      " |          The returned object is a shallow copy. It contains references\n",
      " |          to the module's parameters and buffers.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Currently ``state_dict()`` also accepts positional arguments for\n",
      " |          ``destination``, ``prefix`` and ``keep_vars`` in order. However,\n",
      " |          this is being deprecated and keyword arguments will be enforced in\n",
      " |          future releases.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Please avoid the use of argument ``destination`` as it is not\n",
      " |          designed for end-users.\n",
      " |      \n",
      " |      Args:\n",
      " |          destination (dict, optional): If provided, the state of module will\n",
      " |              be updated into the dict and the same object is returned.\n",
      " |              Otherwise, an ``OrderedDict`` will be created and returned.\n",
      " |              Default: ``None``.\n",
      " |          prefix (str, optional): a prefix added to parameter and buffer\n",
      " |              names to compose the keys in state_dict. Default: ``''``.\n",
      " |          keep_vars (bool, optional): by default the :class:`~torch.Tensor` s\n",
      " |              returned in the state dict are detached from autograd. If it's\n",
      " |              set to ``True``, detaching will not be performed.\n",
      " |              Default: ``False``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(memory_format=torch.channels_last)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point or complex :attr:`dtype`\\ s. In addition, this method will\n",
      " |      only cast the floating point or complex parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\n",
      " |              the parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
      " |              format for 4D parameters and buffers in this module (keyword\n",
      " |              only argument)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA1)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.3741+0.j,  0.2382+0.j],\n",
      " |                  [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n",
      " |          >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n",
      " |          tensor([[0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n",
      " |  \n",
      " |  to_empty(self: ~T, *, device: Union[str, torch.device], recurse: bool = True) -> ~T\n",
      " |      Moves the parameters and buffers to the specified device without copying storage.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): The desired device of the parameters\n",
      " |              and buffers in this module.\n",
      " |          recurse (bool): Whether parameters and buffers of submodules should\n",
      " |              be recursively moved to the specified device.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  train(self: ~T, mode: bool = True) -> ~T\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  xpu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the XPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on XPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self, set_to_none: bool = True) -> None\n",
      " |      Resets gradients of all model parameters. See similar function\n",
      " |      under :class:`torch.optim.Optimizer` for more context.\n",
      " |      \n",
      " |      Args:\n",
      " |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
      " |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  T_destination = ~T_destination\n",
      " |  \n",
      " |  call_super_init = False\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(encoding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaussian_splatting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
