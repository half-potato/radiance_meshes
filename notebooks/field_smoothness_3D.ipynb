{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aedf209-d4a8-4367-81b2-4ead02813bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dronelab/delaunay_rasterization\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "VERSION = 9\n",
    "if VERSION is not None:\n",
    "    os.environ[\"CC\"] = f\"/usr/bin/gcc-{VERSION}\"\n",
    "    os.environ[\"CXX\"] = f\"/usr/bin/g++-{VERSION}\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path(os.path.abspath('')).parent))\n",
    "print(str(Path(os.path.abspath('')).parent))\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils import topo_utils\n",
    "\n",
    "from gDel3D.build.gdel3d import Del\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from utils.compare_quad import setup_camera\n",
    "from utils.train_util import render\n",
    "from data.camera import Camera\n",
    "from models.ingp_color import pre_calc_cell_values, compute_vertex_colors_from_field, calculate_circumcenters_torch\n",
    "from utils.graphics_utils import l2_normalize_th\n",
    "import mediapy\n",
    "\n",
    "torch.set_printoptions(precision=10)\n",
    "\n",
    "tile_size = 16\n",
    "height = 200\n",
    "width = 200\n",
    "fov = 60\n",
    "viewmat = torch.eye(4)\n",
    "\n",
    "viewmat, projection_matrix, cam_pos, fovy, fovx, fx, fy = setup_camera(height, width, fov, viewmat)\n",
    "# Now extract R,T from viewmat\n",
    "# If viewmat is truly \"World->View\", then R is top-left 3x3, T is top-right 3x1\n",
    "# V = torch.inverse(viewmat)\n",
    "V = viewmat\n",
    "R = V[:3, :3].T\n",
    "T = V[:3, 3]\n",
    "\n",
    "# Create a blank image for the camera\n",
    "blank_image = torch.zeros((3, height, width), device=\"cuda\")\n",
    "\n",
    "# Instantiate the camera\n",
    "camera = Camera(\n",
    "    colmap_id = 0,\n",
    "    R = R.cpu().numpy(),\n",
    "    T = T.cpu().numpy(),\n",
    "    fovx = fovx,\n",
    "    fovy = fovy,\n",
    "    image = blank_image,\n",
    "    gt_alpha_mask = None,\n",
    "    uid = 0,\n",
    "    cx = -1,\n",
    "    cy = -1,\n",
    "    trans = np.array([0.0, 0.0, 0.0]), # or any translation offset you need\n",
    "    scale = 1.0,\n",
    "    data_device = \"cuda\",\n",
    "    # You can add any extra distortions, exposure, etc. you might need\n",
    ")\n",
    "\n",
    "vertices = torch.rand((200, 3), device='cuda')\n",
    "velocity = l2_normalize_th(torch.rand((200, 3), device='cuda'))\n",
    "\n",
    "frames = []\n",
    "\n",
    "def field(xyz, scale=0.05):\n",
    "    # Unpack coordinates\n",
    "    x, y, z = xyz[..., 0], xyz[..., 1], xyz[..., 2]\n",
    "    \n",
    "    # Base color intercepts\n",
    "    c0 = torch.sin(scale * x)\n",
    "    c1 = torch.cos(scale * y)\n",
    "    c2 = torch.sin(scale * z)\n",
    "    \n",
    "    # Gradients: 9 coefficients (to be reshaped as (3,3) per point if needed)\n",
    "    c3  = torch.cos(scale * x)\n",
    "    c4  = torch.sin(scale * (x + y))\n",
    "    c5  = torch.cos(scale * (x + z))\n",
    "    c6  = torch.sin(scale * (y - x))\n",
    "    c7  = torch.cos(scale * y)\n",
    "    c8  = torch.sin(scale * (y + z))\n",
    "    c9  = torch.cos(scale * (z - x))\n",
    "    c10 = torch.sin(scale * (z - y))\n",
    "    c11 = torch.cos(scale * z)\n",
    "    \n",
    "    # Extra coefficient\n",
    "    c12 = torch.sin(scale * (x * y * z))\n",
    "    \n",
    "    # Stack all coefficients along the last dimension\n",
    "    return torch.stack([c0, c1, c2, c3, c4, c5, c6, c7, c8, c9, c10, c11, c12], dim=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855ab626-b667-4f49-a26b-69ab7f4eb87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    print(i)\n",
    "    vertices += velocity * 0.01\n",
    "    model = lambda x: x\n",
    "    model.vertices = vertices\n",
    "\n",
    "    # Convert to tensor and move to CUDA\n",
    "    v = Del(vertices.shape[0])\n",
    "    indices_np, prev = v.compute(vertices.detach().cpu())\n",
    "    indices_np = indices_np.numpy()\n",
    "    indices_np = indices_np[(indices_np < vertices.shape[0]).all(axis=1)]\n",
    "    indices = torch.as_tensor(indices_np).cuda()\n",
    "    \n",
    "    model.vertex_color = torch.ones((1), device='cuda')\n",
    "\n",
    "    circumcenter, radius = calculate_circumcenters_torch(vertices[indices].double())\n",
    "    output = field(circumcenter)\n",
    "    density = (output[:, 0:1]-1).exp()\n",
    "    field_samples = output[:, 1:]\n",
    "    vcolors = compute_vertex_colors_from_field(\n",
    "        vertices[indices].detach(), field_samples.float(), circumcenter.float().detach())\n",
    "    vcolors = torch.nn.functional.softplus(vcolors, beta=10)\n",
    "    vcolors = vcolors.reshape(-1, 12)\n",
    "    features = torch.cat([\n",
    "        density, vcolors], dim=1)\n",
    "    model.tet_density = features.float()\n",
    "    \n",
    "    model.indices = indices\n",
    "    model.scene_scaling = 1\n",
    "    def get_cell_values(camera, mask=None):\n",
    "        if mask is not None:\n",
    "            return model.vertex_color, model.tet_density[mask]\n",
    "        else:\n",
    "            return model.vertex_color, model.tet_density\n",
    "    model.get_cell_values = get_cell_values\n",
    "    \n",
    "    render_pkg = render(camera, model, tile_size=tile_size, min_t=0, ladder_p=1, pre_multi=1)\n",
    "    torch_image = render_pkg['render'].permute(1, 2, 0)\n",
    "    image = (torch_image.detach().cpu().numpy() * 255).clip(min=0, max=255).astype(np.uint8)\n",
    "    frames.append(image)\n",
    "\n",
    "mediapy.show_video(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab81e77-dba4-45e9-bfe6-983182972c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices += velocity * 0.01\n",
    "model = lambda x: x\n",
    "model.vertices = vertices\n",
    "\n",
    "# Convert to tensor and move to CUDA\n",
    "v = Del(vertices.shape[0])\n",
    "indices_np, prev = v.compute(vertices.detach().cpu())\n",
    "indices_np = indices_np.numpy()\n",
    "indices_np = indices_np[(indices_np < vertices.shape[0]).all(axis=1)]\n",
    "indices = torch.as_tensor(indices_np).cuda()\n",
    "\n",
    "model.vertex_color = torch.ones((1), device='cuda')\n",
    "\n",
    "circumcenter, radius = calculate_circumcenters_torch(vertices[indices].double())\n",
    "output = field(circumcenter)\n",
    "density = (output[:, 0:1]-1).exp()\n",
    "field_samples = output[:, 1:]\n",
    "vcolors = compute_vertex_colors_from_field(\n",
    "    vertices[indices].detach(), field_samples.float(), circumcenter.float().detach())\n",
    "vcolors = torch.nn.functional.softplus(vcolors, beta=10)\n",
    "vcolors = vcolors.reshape(-1, 12)\n",
    "features = torch.cat([\n",
    "    density, vcolors], dim=1)\n",
    "model.tet_density = features.float()\n",
    "\n",
    "model.indices = indices\n",
    "model.scene_scaling = 1\n",
    "def get_cell_values(camera, mask=None):\n",
    "    if mask is not None:\n",
    "        return model.vertex_color, model.tet_density[mask]\n",
    "    else:\n",
    "        return model.vertex_color, model.tet_density\n",
    "model.get_cell_values = get_cell_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f72f76-cf5d-4805-a6ee-51b62bc5c87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "render_pkg = render(camera, model, tile_size=tile_size, min_t=0, ladder_p=1, pre_multi=1)\n",
    "torch_image = render_pkg['render'].permute(1, 2, 0)\n",
    "image = (torch_image.detach().cpu().numpy() * 255).clip(min=0, max=255).astype(np.uint8)\n",
    "frames.append(image)\n",
    "\n",
    "mediapy.show_video(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7887b11e-1642-4954-bbea-9c8a838d3691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"show_videos\" style=\"border-spacing:0px;\"><tr><td style=\"padding:1px;\"><video controls width=\"200\" height=\"200\" style=\"object-fit:cover;\" loop autoplay muted>\n",
       "      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\"/>\n",
       "      This browser does not support the video tag.\n",
       "      </video></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f0a953-4063-4bae-a95b-598d549b7fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
